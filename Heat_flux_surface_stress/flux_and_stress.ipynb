{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285f1638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as mplstyle\n",
    "import cartopy.crs ascrs\n",
    "import cartopy.feature as cfeature\n",
    "import xarray as xr\n",
    "\n",
    "mplstyle.use(['ggplot', 'fast'])\n",
    "\n",
    "from Heat_flux_surface_stress.open_atmos_files import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f0ef14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/lustre/storeB/project/nwp/havvind/atmosphere/turbines/2022/03/01/12/fc2022030112_turbines.nc'\n",
    "atmos = xr.open_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2748f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = {\n",
    "\"02\": 28,  # February (not a leap year in 2022)\n",
    "\"03\": 31,  # March\n",
    "\"04\": 30,  # April\n",
    "\"05\": 31,  # May\n",
    "\"06\": 30   # June\n",
    "         }\n",
    "\n",
    "times = [\"00\", \"03\", \"09\", \"12\", \"15\", \"18\", \"21\"]\n",
    "\n",
    "# Making a list of paths to turbine datasets\n",
    "base_path_turb = '/lustre/storeB/project/nwp/havvind/atmosphere/turbines/2022'\n",
    "files_turb = []\n",
    "\n",
    "for month, days in months.items():\n",
    "    for day in range(1, days + 1):\n",
    "        day_str = f\"{day:02}\"  # Formatting day as two digits\n",
    "        for time in times:\n",
    "            # Construct the file name\n",
    "            file_name_turb = f'fc2022{month}{day_str}{time}_turbines.nc'\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(base_path_turb, month, day_str, time, file_name_turb)\n",
    "            files_turb.append(file_path)\n",
    "\n",
    "# Making list of reference datasets\n",
    "base_path_ref = '/lustre/storeB/project/nwp/havvind/atmosphere/reference/2022'\n",
    "files_ref = []\n",
    "\n",
    "for month, days in months.items():\n",
    "    for day in range(1, days + 1):\n",
    "        day_str = f\"{day:02}\"  # Formatting day as two digits\n",
    "        for time in times:\n",
    "            # Construct the file name\n",
    "            file_name_ref= f'fc2022{month}{day_str}{time}_reference.nc'\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(base_path_ref, month, day_str, time, file_name_ref)\n",
    "            files_ref.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ab93e70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Resulting object does not have monotonic global indexes along dimension time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ref \u001b[38;5;241m=\u001b[39m open_dataset_heatflux_surfstress(files_ref)\n",
      "File \u001b[0;32m~/sommer_25/MET_sommer25/Heat_flux_surface_stress/open_atmos_files.py:49\u001b[0m, in \u001b[0;36mopen_dataset_heatflux_surfstress\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset_heatflux_surfstress\u001b[39m(files):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    Opens a list of atmospheric output files.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    Returns xArray DataSet with wanted variables\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    for investigating heat fluxes and surface stress.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     full_ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     variables \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSFX_H\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSFX_LE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSFX_FMV\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     52\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintegral_of_surface_net_downward_shortwave_flux_wrt_time\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     53\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintegral_of_surface_net_downward_longwave_flux_wrt_time\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     54\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintegral_of_surface_net_downward_latent_heat_evaporation_flux_wrt_time\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     55\u001b[0m                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintegral_of_surface_downward_sensible_heat_flux_wrt_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     57\u001b[0m     ds_sub \u001b[38;5;241m=\u001b[39m full_ds[variables]\n",
      "File \u001b[0;32m/modules/rhel8/conda/install/envs/production-10-2022/lib/python3.9/site-packages/xarray/backends/api.py:1000\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m     combined \u001b[38;5;241m=\u001b[39m _nested_combine(\n\u001b[1;32m    988\u001b[0m         datasets,\n\u001b[1;32m    989\u001b[0m         concat_dims\u001b[38;5;241m=\u001b[39mconcat_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    995\u001b[0m         combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    996\u001b[0m     )\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m combine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby_coords\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# Redo ordering from coordinates, ignoring how they were ordered\u001b[39;00m\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# previously\u001b[39;00m\n\u001b[0;32m-> 1000\u001b[0m     combined \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_by_coords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is an invalid option for the keyword argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ``combine``\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(combine)\n\u001b[1;32m   1012\u001b[0m     )\n",
      "File \u001b[0;32m/modules/rhel8/conda/install/envs/production-10-2022/lib/python3.9/site-packages/xarray/core/combine.py:982\u001b[0m, in \u001b[0;36mcombine_by_coords\u001b[0;34m(data_objects, compat, data_vars, coords, fill_value, join, combine_attrs, datasets)\u001b[0m\n\u001b[1;32m    980\u001b[0m     concatenated_grouped_by_data_vars \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mvars\u001b[39m, datasets_with_same_vars \u001b[38;5;129;01min\u001b[39;00m grouped_by_vars:\n\u001b[0;32m--> 982\u001b[0m         concatenated \u001b[38;5;241m=\u001b[39m \u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    991\u001b[0m         concatenated_grouped_by_data_vars\u001b[38;5;241m.\u001b[39mappend(concatenated)\n\u001b[1;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m    994\u001b[0m     concatenated_grouped_by_data_vars,\n\u001b[1;32m    995\u001b[0m     compat\u001b[38;5;241m=\u001b[39mcompat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m     combine_attrs\u001b[38;5;241m=\u001b[39mcombine_attrs,\n\u001b[1;32m    999\u001b[0m )\n",
      "File \u001b[0;32m/modules/rhel8/conda/install/envs/production-10-2022/lib/python3.9/site-packages/xarray/core/combine.py:655\u001b[0m, in \u001b[0;36m_combine_single_variable_hypercube\u001b[0;34m(datasets, fill_value, data_vars, coords, compat, join, combine_attrs)\u001b[0m\n\u001b[1;32m    653\u001b[0m     indexes \u001b[38;5;241m=\u001b[39m concatenated\u001b[38;5;241m.\u001b[39mindexes\u001b[38;5;241m.\u001b[39mget(dim)\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (indexes\u001b[38;5;241m.\u001b[39mis_monotonic_increasing \u001b[38;5;129;01mor\u001b[39;00m indexes\u001b[38;5;241m.\u001b[39mis_monotonic_decreasing):\n\u001b[0;32m--> 655\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    656\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResulting object does not have monotonic\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    657\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m global indexes along dimension \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dim)\n\u001b[1;32m    658\u001b[0m         )\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenated\n",
      "\u001b[0;31mValueError\u001b[0m: Resulting object does not have monotonic global indexes along dimension time"
     ]
    }
   ],
   "source": [
    "ref = open_dataset_heatflux_surfstress(files_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299ed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:production-10-2022] *",
   "language": "python",
   "name": "conda-env-production-10-2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
